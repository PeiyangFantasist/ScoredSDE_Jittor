{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540b2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0721 16:24:37.768642 44 compiler.py:956] Jittor(1.3.9.14) src: /home/a516/anaconda3/envs/Jittor/lib/python3.8/site-packages/jittor\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:37.774011 44 compiler.py:957] g++ at /usr/bin/g++(12.3.0)\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:37.774549 44 compiler.py:958] cache_path: /home/a516/.cache/jittor/jt1.3.9/g++12.3.0/py3.8.20/Linux-6.6.87.2xef/13thGenIntelRCx37/4832/default\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:37.778372 44 __init__.py:412] Found nvcc(12.8.61) at /usr/local/cuda-12.8/bin/nvcc.\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:37.855370 44 __init__.py:412] Found addr2line(2.42) at /usr/bin/addr2line.\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:37.916179 44 compiler.py:1013] cuda key:cu12.8.61\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:38.215488 44 __init__.py:227] Total mem: 7.56GB, using 2 procs for compiling.\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:38.277619 44 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:39.007779 44 init.cc:63] Found cuda archs: [89,]\u001b[m\n",
      "\u001b[38;5;3m[w 0721 16:24:39.198686 44 compile_extern.py:203] CUDA related path found in LD_LIBRARY_PATH or PATH, This path may cause jittor found the wrong libs, please unset LD_LIBRARY_PATH and remove cuda lib path in Path. \n",
      "Or you can let jittor install cuda for you: `python3.x -m jittor_utils.install_cuda`\u001b[m\n",
      "\u001b[38;5;2m[i 0721 16:24:39.422555 44 cuda_flags.cc:49] CUDA enabled.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æµ‹è¯• VPSDE ===\n",
      "  sde() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  marginal_prob() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  å…ˆéªŒé‡‡æ ·/å¯¹æ•°æ¦‚ç‡ æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  discretize() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "\n",
      "=== æµ‹è¯• subVPSDE ===\n",
      "  sde() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  marginal_prob() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  å…ˆéªŒé‡‡æ ·/å¯¹æ•°æ¦‚ç‡ æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  discretize() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "\n",
      "=== æµ‹è¯• VESDE ===\n",
      "  sde() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  marginal_prob() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  å…ˆéªŒé‡‡æ ·/å¯¹æ•°æ¦‚ç‡ æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "  discretize() æµ‹è¯•é€šè¿‡ âœ”ï¸\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jittor as jt\n",
    "from sde_lib import VPSDE, subVPSDE, VESDE  # ä»ä½ çš„æ¨¡å—å¯¼å…¥\n",
    "jt.flags.use_cuda = 1\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "# ------------------------- é€šç”¨æµ‹è¯•å·¥å…· -------------------------\n",
    "def test_sde_core(sde_class, N=1000):\n",
    "    \"\"\"æµ‹è¯• SDE æ ¸å¿ƒåŠŸèƒ½ï¼šåˆå§‹åŒ– + sde + marginal_prob + å…ˆéªŒé‡‡æ ·/å¯¹æ•°æ¦‚ç‡\"\"\"\n",
    "    # 1. åˆå§‹åŒ– SDE\n",
    "    sde = sde_class(N=N)\n",
    "    print(f\"=== æµ‹è¯• {sde_class.__name__} ===\")\n",
    "\n",
    "    # 2. æ„é€ æµ‹è¯•æ•°æ®ï¼ˆç®€åŒ–ç»´åº¦ï¼šbatch=2, é€šé“=1, å°ºå¯¸=4x4ï¼‰\n",
    "    batch_size = 2\n",
    "    x = jt.randn(batch_size, 1, 4, 4)  # éšæœºè¾“å…¥\n",
    "    t = jt.rand(batch_size)             # éšæœºæ—¶é—´æ­¥ï¼ˆ0~1ï¼‰\n",
    "\n",
    "    # 3. æµ‹è¯• sde()ï¼šæ¼‚ç§»é¡¹(drift)å’Œæ‰©æ•£é¡¹(diffusion)\n",
    "    drift, diffusion = sde.sde(x, t)\n",
    "    assert drift.shape == x.shape, \"sde() æ¼‚ç§»é¡¹å½¢çŠ¶é”™è¯¯\"\n",
    "    assert diffusion.shape == (batch_size,), \"sde() æ‰©æ•£é¡¹å½¢çŠ¶é”™è¯¯\"\n",
    "    print(\"  sde() æµ‹è¯•é€šè¿‡ âœ”ï¸\")\n",
    "\n",
    "    # 4. æµ‹è¯• marginal_prob()ï¼šå‡å€¼(mean)å’Œæ ‡å‡†å·®(std)\n",
    "    mean, std = sde.marginal_prob(x, t)\n",
    "    assert mean.shape == x.shape, \"marginal_prob() å‡å€¼å½¢çŠ¶é”™è¯¯\"\n",
    "    assert std.shape == (batch_size,), \"marginal_prob() æ ‡å‡†å·®å½¢çŠ¶é”™è¯¯\"\n",
    "    print(\"  marginal_prob() æµ‹è¯•é€šè¿‡ âœ”ï¸\")\n",
    "\n",
    "    # 5. æµ‹è¯•å…ˆéªŒé‡‡æ · + å¯¹æ•°æ¦‚ç‡\n",
    "    sample_shape = (batch_size, 1, 4, 4)\n",
    "    sample = sde.prior_sampling(sample_shape)\n",
    "    assert sample.shape == sample_shape, \"prior_sampling() å½¢çŠ¶é”™è¯¯\"\n",
    "    \n",
    "    logp = sde.prior_logp(sample)\n",
    "    assert logp.shape == (batch_size,), \"prior_logp() å½¢çŠ¶é”™è¯¯\"\n",
    "    print(\"  å…ˆéªŒé‡‡æ ·/å¯¹æ•°æ¦‚ç‡ æµ‹è¯•é€šè¿‡ âœ”ï¸\")\n",
    "\n",
    "    # 6. æµ‹è¯•ç¦»æ•£åŒ–(discretize)\n",
    "    f, G = sde.discretize(x, t)\n",
    "    assert f.shape == x.shape, \"discretize() æ¼‚ç§»é¡¹ç¦»æ•£åŒ–é”™è¯¯\"\n",
    "    assert G.shape == (batch_size,), \"discretize() æ‰©æ•£é¡¹ç¦»æ•£åŒ–é”™è¯¯\"\n",
    "    print(\"  discretize() æµ‹è¯•é€šè¿‡ âœ”ï¸\\n\")\n",
    "\n",
    "\n",
    "# ------------------------- æ‰§è¡Œæµ‹è¯• -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # æµ‹è¯•æ‰€æœ‰ SDE ç±»\n",
    "    test_sde_core(VPSDE)\n",
    "    test_sde_core(subVPSDE)\n",
    "    test_sde_core(VESDE, N=1000)  # VESDE å‚æ•°å…¼å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e77e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=jt.Var([1,2])\n",
    "x.detach().cpu().numpy().reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbbd9bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-88a15c3ad9a0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python æœç´¢è·¯å¾„ï¼ˆç¡®ä¿èƒ½æ‰¾åˆ° models æ–‡ä»¶å¤¹ï¼‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjittor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import sys\n",
    "import os\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python æœç´¢è·¯å¾„ï¼ˆç¡®ä¿èƒ½æ‰¾åˆ° models æ–‡ä»¶å¤¹ï¼‰\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "import jittor as jt\n",
    "import numpy as np\n",
    "# ä» models.utils å¯¼å…¥éœ€è¦æµ‹è¯•çš„å‡½æ•°/ç±»\n",
    "from models.utils import (\n",
    "    register_model, get_model, create_model,\n",
    "    to_flattened_numpy, from_flattened_numpy,\n",
    "    get_model_fn, get_score_fn\n",
    ")\n",
    "import sde_lib  # å‡è®¾ sde_lib ä¸ models åŒçº§æˆ–å·²åœ¨æœç´¢è·¯å¾„ä¸­\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–Jittor\n",
    "jt.init()\n",
    "\n",
    "\n",
    "# å®šä¹‰æµ‹è¯•ç”¨çš„æ¨¡å‹å’ŒSDEï¼ˆä¸ä¹‹å‰ç›¸åŒï¼Œç”¨äºæ¨¡æ‹Ÿæµ‹è¯•ç¯å¢ƒï¼‰\n",
    "@register_model(name=\"test_model\")\n",
    "class TestModel(jt.nn.Module):\n",
    "    \"\"\"ç”¨äºæµ‹è¯•çš„ç®€å•æ¨¡å‹\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def execute(self, x, labels):\n",
    "        \"\"\"ç®€å•è¿”å›è¾“å…¥xçš„å‰¯æœ¬ï¼ˆæ¨¡æ‹Ÿæ¨¡å‹è¾“å‡ºï¼‰\"\"\"\n",
    "        return x.clone()\n",
    "\n",
    "\n",
    "class MockVPSDE(sde_lib.VPSDE):\n",
    "    \"\"\"æ¨¡æ‹ŸVPSDEç”¨äºæµ‹è¯•\"\"\"\n",
    "    def __init__(self):\n",
    "        self.N = 10  # æ—¶é—´æ­¥æ•°é‡\n",
    "        self.sqrt_1m_alphas_cumprod = jt.linspace(0.1, 1.0, self.N)  # æ¨¡æ‹Ÿå‚æ•°\n",
    "\n",
    "    def marginal_prob(self, x, t):\n",
    "        \"\"\"è¿”å›å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆæ¨¡æ‹Ÿï¼‰\"\"\"\n",
    "        return x, jt.ones_like(x) * 0.5  # æ ‡å‡†å·®å›ºå®šä¸º0.5\n",
    "\n",
    "\n",
    "class MockVESDE(sde_lib.VESDE):\n",
    "    \"\"\"æ¨¡æ‹ŸVESDEç”¨äºæµ‹è¯•\"\"\"\n",
    "    def __init__(self):\n",
    "        self.T = 1.0  # æ€»æ—¶é—´\n",
    "        self.N = 10  # ç¦»æ•£æ—¶é—´æ­¥æ•°é‡\n",
    "\n",
    "\n",
    "class TestUtils(unittest.TestCase):\n",
    "    \"\"\"æµ‹è¯•ä¿®æ”¹åçš„å·¥å…·å‡½æ•°\"\"\"\n",
    "\n",
    "    def test_register_and_get_model(self):\n",
    "        \"\"\"æµ‹è¯•æ¨¡å‹æ³¨å†Œä¸è·å–\"\"\"\n",
    "        # æ£€æŸ¥æ˜¯å¦èƒ½æ­£ç¡®è·å–å·²æ³¨å†Œçš„æ¨¡å‹\n",
    "        model_cls = get_model(\"test_model\")\n",
    "        self.assertEqual(model_cls.__name__, \"TestModel\")\n",
    "\n",
    "        # æµ‹è¯•æœªæ³¨å†Œæ¨¡å‹çš„é”™è¯¯\n",
    "        with self.assertRaises(KeyError):\n",
    "            get_model(\"unregistered_model\")\n",
    "\n",
    "    def test_from_flattened_numpy(self):\n",
    "        \"\"\"æµ‹è¯•ä»å±•å¹³çš„numpyæ•°ç»„åˆ›å»ºJittorå¼ é‡\"\"\"\n",
    "        # ç”ŸæˆåŸå§‹æ•°æ®\n",
    "        original = np.random.rand(2, 3, 4)  # å½¢çŠ¶(2,3,4)\n",
    "        flattened = original.flatten()  # å±•å¹³ä¸º(24,)\n",
    "\n",
    "        # è½¬æ¢ä¸ºJittorå¼ é‡\n",
    "        recovered = from_flattened_numpy(flattened, shape=(2, 3, 4))\n",
    "\n",
    "        # éªŒè¯å½¢çŠ¶å’Œæ•°æ®\n",
    "        self.assertEqual(recovered.shape, (2, 3, 4))\n",
    "        np.testing.assert_allclose(recovered.numpy(), original, rtol=1e-6)\n",
    "\n",
    "    def test_to_flattened_numpy(self):\n",
    "        \"\"\"æµ‹è¯•å°†Jittorå¼ é‡å±•å¹³ä¸ºnumpyæ•°ç»„\"\"\"\n",
    "        # åˆ›å»ºJittorå¼ é‡\n",
    "        x = jt.array(np.random.rand(2, 3, 4))\n",
    "\n",
    "        # å±•å¹³ä¸ºnumpy\n",
    "        flattened = to_flattened_numpy(x)\n",
    "\n",
    "        # éªŒè¯å½¢çŠ¶å’Œæ•°æ®\n",
    "        self.assertEqual(flattened.shape, (24,))  # 2*3*4=24\n",
    "        np.testing.assert_allclose(flattened, x.numpy().flatten(), rtol=1e-6)\n",
    "\n",
    "    def test_create_model(self):\n",
    "        \"\"\"æµ‹è¯•æ¨¡å‹åˆ›å»ºå‡½æ•°\"\"\"\n",
    "        # æ¨¡æ‹Ÿé…ç½®\n",
    "        class MockConfig:\n",
    "            class model:\n",
    "                name = \"test_model\"\n",
    "        config = MockConfig()\n",
    "\n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        model = create_model(config)\n",
    "\n",
    "        # éªŒè¯æ¨¡å‹ç±»å‹\n",
    "        self.assertIsInstance(model, TestModel)\n",
    "\n",
    "    def test_get_model_fn(self):\n",
    "        \"\"\"æµ‹è¯•æ¨¡å‹å‡½æ•°åŒ…è£…ï¼ˆè®­ç»ƒ/è¯„ä¼°æ¨¡å¼ï¼‰\"\"\"\n",
    "        # åˆ›å»ºæ¨¡å‹å’Œé…ç½®\n",
    "        model = TestModel(config=None)\n",
    "        train_fn = get_model_fn(model, train=True)\n",
    "        eval_fn = get_model_fn(model, train=False)\n",
    "\n",
    "        # æµ‹è¯•è¾“å…¥è¾“å‡ºï¼ˆæ¨¡å‹ç®€å•è¿”å›xï¼Œè¿™é‡ŒéªŒè¯è°ƒç”¨æ˜¯å¦æ­£å¸¸ï¼‰\n",
    "        x = jt.array(np.random.rand(2, 3))\n",
    "        labels = jt.array([1, 2])\n",
    "\n",
    "        train_out = train_fn(x, labels)\n",
    "        eval_out = eval_fn(x, labels)\n",
    "\n",
    "        # éªŒè¯è¾“å‡ºä¸è¾“å…¥ä¸€è‡´ï¼ˆå› ä¸ºTestModelè¿”å›xï¼‰\n",
    "        self.assertTrue(jt.allclose(train_out, x))\n",
    "        self.assertTrue(jt.allclose(eval_out, x))\n",
    "\n",
    "    def test_get_score_fn_vpsde(self):\n",
    "        \"\"\"æµ‹è¯•VPSDEçš„åˆ†æ•°å‡½æ•°åŒ…è£…\"\"\"\n",
    "        # æ¨¡æ‹ŸSDEå’Œæ¨¡å‹\n",
    "        sde = MockVPSDE()\n",
    "        model = TestModel(config=None)  # æ¨¡å‹è¿”å›xï¼ˆè¿™é‡Œç”¨äºæµ‹è¯•è®¡ç®—é€»è¾‘ï¼‰\n",
    "        score_fn = get_score_fn(sde, model, continuous=False)\n",
    "\n",
    "        # æµ‹è¯•è¾“å…¥\n",
    "        x = jt.array(np.random.rand(2, 3, 3, 1))  # å‡è®¾æ˜¯å›¾åƒæ•°æ®(æ‰¹é‡, H, W, C)\n",
    "        t = jt.array([0.1, 0.5])  # æ—¶é—´æ­¥\n",
    "\n",
    "        # è®¡ç®—åˆ†æ•°\n",
    "        score = score_fn(x, t)\n",
    "\n",
    "        # éªŒè¯é€»è¾‘ï¼šVPSDEçš„åˆ†æ•°åº”ä¸º -model_out / std\n",
    "        # æ¨¡å‹è¿”å›xï¼Œå› æ­¤scoreåº”çº¦ä¸º -x / stdï¼ˆstdæ¥è‡ªsde.sqrt_1m_alphas_cumprodï¼‰\n",
    "        labels = t * (sde.N - 1)  # ç¦»æ•£æ—¶é—´æ ‡ç­¾\n",
    "        std = sde.sqrt_1m_alphas_cumprod[labels.long()]\n",
    "        expected_score = -x / std[:, None, None, None]  # å¹¿æ’­stdåˆ°xçš„å½¢çŠ¶\n",
    "\n",
    "        self.assertTrue(jt.allclose(score, expected_score, rtol=1e-6))\n",
    "\n",
    "    def test_get_score_fn_vesde(self):\n",
    "        \"\"\"æµ‹è¯•VESDEçš„åˆ†æ•°å‡½æ•°åŒ…è£…\"\"\"\n",
    "        # æ¨¡æ‹ŸSDEå’Œæ¨¡å‹\n",
    "        sde = MockVESDE()\n",
    "        model = TestModel(config=None)  # æ¨¡å‹è¿”å›x\n",
    "        score_fn = get_score_fn(sde, model, continuous=False)\n",
    "\n",
    "        # æµ‹è¯•è¾“å…¥\n",
    "        x = jt.array(np.random.rand(2, 3, 3, 1))\n",
    "        t = jt.array([0.2, 0.8])  # æ—¶é—´æ­¥\n",
    "\n",
    "        # è®¡ç®—åˆ†æ•°\n",
    "        score = score_fn(x, t)\n",
    "\n",
    "        # éªŒè¯é€»è¾‘ï¼šVESDEçš„åˆ†æ•°ç›´æ¥è¿”å›model_outï¼ˆæ¨¡å‹è¿”å›xï¼Œå› æ­¤scoreåº”ç­‰äºxï¼‰\n",
    "        self.assertTrue(jt.allclose(score, x, rtol=1e-6))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a73ce86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPSDEåŸºç¡€æ–¹æ³•æµ‹è¯•é€šè¿‡\n",
      "VPSDEåå‘SDEæµ‹è¯•é€šè¿‡\n",
      "subVPSDEåŸºç¡€æ–¹æ³•æµ‹è¯•é€šè¿‡\n",
      "subVPSDEåå‘SDEæµ‹è¯•é€šè¿‡\n",
      "VESDEåŸºç¡€æ–¹æ³•æµ‹è¯•é€šè¿‡\n",
      "VESDEåå‘SDEæµ‹è¯•é€šè¿‡\n",
      "æ‰€æœ‰SDEæµ‹è¯•å‡é€šè¿‡ï¼\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Abstract SDE classes, Reverse SDE, and VE/VP SDEs.\"\"\"\n",
    "import abc\n",
    "import jittor as jt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SDE(abc.ABC):\n",
    "  \"\"\"SDE abstract class. Functions are designed for a mini-batch of inputs.\"\"\"\n",
    "\n",
    "  def __init__(self, N):\n",
    "    \"\"\"Construct an SDE.\n",
    "\n",
    "    Args:\n",
    "      N: number of discretization time steps.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.N = N\n",
    "\n",
    "  @property\n",
    "  @abc.abstractmethod\n",
    "  def T(self):\n",
    "    \"\"\"End time of the SDE.\"\"\"\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def sde(self, x, t):\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def marginal_prob(self, x, t):\n",
    "    \"\"\"Parameters to determine the marginal distribution of the SDE, $p_t(x)$.\"\"\"\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def prior_sampling(self, shape):\n",
    "    \"\"\"Generate one sample from the prior distribution, $p_T(x)$.\"\"\"\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def prior_logp(self, z):\n",
    "    \"\"\"Compute log-density of the prior distribution.\n",
    "\n",
    "    Useful for computing the log-likelihood via probability flow ODE.\n",
    "\n",
    "    Args:\n",
    "      z: latent code\n",
    "    Returns:\n",
    "      log probability density\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "  def discretize(self, x, t):\n",
    "    \"\"\"Discretize the SDE in the form: x_{i+1} = x_i + f_i(x_i) + G_i z_i.\n",
    "\n",
    "    Useful for reverse diffusion sampling and probabiliy flow sampling.\n",
    "    Defaults to Euler-Maruyama discretization.\n",
    "\n",
    "    Args:\n",
    "      x: a torch tensor\n",
    "      t: a torch float representing the time step (from 0 to `self.T`)\n",
    "\n",
    "    Returns:\n",
    "      f, G\n",
    "    \"\"\"\n",
    "    dt = 1 / self.N\n",
    "    drift, diffusion = self.sde(x, t)\n",
    "    f = drift * dt\n",
    "    G = diffusion * jt.sqrt(jt.array(dt))\n",
    "    return f, G\n",
    "\n",
    "  def reverse(self, score_fn, probability_flow=False):\n",
    "    \"\"\"Create the reverse-time SDE/ODE.\n",
    "\n",
    "    Args:\n",
    "      score_fn: A time-dependent score-based model that takes x and t and returns the score.\n",
    "      probability_flow: If `True`, create the reverse-time ODE used for probability flow sampling.\n",
    "    \"\"\"\n",
    "    N = self.N\n",
    "    T = self.T\n",
    "    sde_fn = self.sde\n",
    "    discretize_fn = self.discretize\n",
    "\n",
    "    # Build the class for reverse-time SDE.\n",
    "    class RSDE(self.__class__):\n",
    "      def __init__(self):\n",
    "        self.N = N\n",
    "        self.probability_flow = probability_flow\n",
    "\n",
    "      @property\n",
    "      def T(self):\n",
    "        return T\n",
    "\n",
    "      def sde(self, x, t):\n",
    "        \"\"\"Create the drift and diffusion functions for the reverse SDE/ODE.\"\"\"\n",
    "        drift, diffusion = sde_fn(x, t)\n",
    "        score = score_fn(x, t)\n",
    "        drift = drift - diffusion[:, None, None, None] ** 2 * score * (0.5 if self.probability_flow else 1.)\n",
    "        # Set the diffusion function to zero for ODEs.\n",
    "        diffusion = 0. if self.probability_flow else diffusion\n",
    "        return drift, diffusion\n",
    "\n",
    "      def discretize(self, x, t):\n",
    "        \"\"\"Create discretized iteration rules for the reverse diffusion sampler.\"\"\"\n",
    "        f, G = discretize_fn(x, t)\n",
    "        rev_f = f - G[:, None, None, None] ** 2 * score_fn(x, t) * (0.5 if self.probability_flow else 1.)\n",
    "        rev_G = jt.zeros_like(G) if self.probability_flow else G\n",
    "        return rev_f, rev_G\n",
    "\n",
    "    return RSDE()\n",
    "\n",
    "\n",
    "class VPSDE(SDE):\n",
    "  def __init__(self, beta_min=0.1, beta_max=20, N=1000):\n",
    "    \"\"\"Construct a Variance Preserving SDE.\n",
    "\n",
    "    Args:\n",
    "      beta_min: value of beta(0)\n",
    "      beta_max: value of beta(1)\n",
    "      N: number of discretization steps\n",
    "    \"\"\"\n",
    "    super().__init__(N)\n",
    "    self.beta_0 = beta_min\n",
    "    self.beta_1 = beta_max\n",
    "    self.N = N\n",
    "    self.discrete_betas = jt.linspace(beta_min / N, beta_max / N, N)\n",
    "    self.alphas = 1. - self.discrete_betas\n",
    "    self.alphas_cumprod = jt.cumprod(self.alphas, dim=0)\n",
    "    self.sqrt_alphas_cumprod = jt.sqrt(self.alphas_cumprod)\n",
    "    self.sqrt_1m_alphas_cumprod = jt.sqrt(1. - self.alphas_cumprod)\n",
    "\n",
    "  @property\n",
    "  def T(self):\n",
    "    return 1\n",
    "\n",
    "  def sde(self, x, t):\n",
    "    beta_t = self.beta_0 + t * (self.beta_1 - self.beta_0)\n",
    "    drift = -0.5 * beta_t[:, None, None, None] * x\n",
    "    diffusion = jt.sqrt(beta_t)\n",
    "    return drift, diffusion\n",
    "\n",
    "  def marginal_prob(self, x, t):\n",
    "    log_mean_coeff = -0.25 * t ** 2 * (self.beta_1 - self.beta_0) - 0.5 * t * self.beta_0\n",
    "    mean = jt.exp(log_mean_coeff[:, None, None, None]) * x\n",
    "    std = jt.sqrt(1. - jt.exp(2. * log_mean_coeff))\n",
    "    return mean, std\n",
    "\n",
    "  def prior_sampling(self, shape):\n",
    "    return jt.randn(*shape)\n",
    "\n",
    "  def prior_logp(self, z):\n",
    "    shape = z.shape\n",
    "    N = np.prod(shape[1:])\n",
    "    logps = -N / 2. * np.log(2 * np.pi) - jt.sum(z ** 2, (1, 2, 3)) / 2.\n",
    "    return logps\n",
    "\n",
    "  def discretize(self, x, t):\n",
    "    \"\"\"DDPM discretization.\"\"\"\n",
    "    timestep = (t * (self.N - 1) / self.T).long()\n",
    "    # Fxxk u\n",
    "    discrete_betas = self.discrete_betas\n",
    "    alphas = self.alphas\n",
    "    \n",
    "    beta = discrete_betas[timestep]\n",
    "    alpha = alphas[timestep]\n",
    "    \n",
    "    sqrt_beta = jt.sqrt(beta)\n",
    "    f = jt.sqrt(alpha)[:, None, None, None] * x - x\n",
    "    G = sqrt_beta\n",
    "    return f, G\n",
    "\n",
    "\n",
    "class subVPSDE(SDE):\n",
    "  def __init__(self, beta_min=0.1, beta_max=20, N=1000):\n",
    "    \"\"\"Construct the sub-VP SDE that excels at likelihoods.\n",
    "\n",
    "    Args:\n",
    "      beta_min: value of beta(0)\n",
    "      beta_max: value of beta(1)\n",
    "      N: number of discretization steps\n",
    "    \"\"\"\n",
    "    super().__init__(N)\n",
    "    self.beta_0 = beta_min\n",
    "    self.beta_1 = beta_max\n",
    "    self.N = N\n",
    "\n",
    "  @property\n",
    "  def T(self):\n",
    "    return 1\n",
    "\n",
    "  def sde(self, x, t):\n",
    "    beta_t = self.beta_0 + t * (self.beta_1 - self.beta_0)\n",
    "    drift = -0.5 * beta_t[:, None, None, None] * x\n",
    "    discount = 1. - jt.exp(-2 * self.beta_0 * t - (self.beta_1 - self.beta_0) * t ** 2)\n",
    "    diffusion = jt.sqrt(beta_t * discount)\n",
    "    return drift, diffusion\n",
    "\n",
    "  def marginal_prob(self, x, t):\n",
    "    log_mean_coeff = -0.25 * t ** 2 * (self.beta_1 - self.beta_0) - 0.5 * t * self.beta_0\n",
    "    mean = jt.exp(log_mean_coeff)[:, None, None, None] * x\n",
    "    std = 1 - jt.exp(2. * log_mean_coeff)\n",
    "    return mean, std\n",
    "\n",
    "  def prior_sampling(self, shape):\n",
    "    return jt.randn(*shape)\n",
    "\n",
    "  def prior_logp(self, z):\n",
    "    shape = z.shape\n",
    "    N = np.prod(shape[1:])\n",
    "    return -N / 2. * np.log(2 * np.pi) - jt.sum(z ** 2, (1, 2, 3)) / 2.\n",
    "\n",
    "\n",
    "class VESDE(SDE):\n",
    "  def __init__(self, sigma_min=0.01, sigma_max=50, N=1000):\n",
    "    \"\"\"Construct a Variance Exploding SDE.\n",
    "\n",
    "    Args:\n",
    "      sigma_min: smallest sigma.\n",
    "      sigma_max: largest sigma.\n",
    "      N: number of discretization steps\n",
    "    \"\"\"\n",
    "    super().__init__(N)\n",
    "    self.sigma_min = sigma_min\n",
    "    self.sigma_max = sigma_max\n",
    "    self.discrete_sigmas = jt.exp(jt.linspace(np.log(self.sigma_min), np.log(self.sigma_max), N))\n",
    "    self.N = N\n",
    "\n",
    "  @property\n",
    "  def T(self):\n",
    "    return 1\n",
    "\n",
    "  def sde(self, x, t):\n",
    "    sigma = self.sigma_min * (self.sigma_max / self.sigma_min) ** t\n",
    "    drift = jt.zeros_like(x)\n",
    "    diffusion = sigma * jt.sqrt(jt.Var(2 * (np.log(self.sigma_max) - np.log(self.sigma_min))))\n",
    "    return drift, diffusion\n",
    "\n",
    "  def marginal_prob(self, x, t):\n",
    "    std = self.sigma_min * (self.sigma_max / self.sigma_min) ** t\n",
    "    mean = x\n",
    "    return mean, std\n",
    "\n",
    "  def prior_sampling(self, shape):\n",
    "    return jt.randn(*shape) * self.sigma_max\n",
    "\n",
    "  def prior_logp(self, z):\n",
    "    shape = z.shape\n",
    "    N = np.prod(shape[1:])\n",
    "    return -N / 2. * np.log(2 * np.pi * self.sigma_max ** 2) - jt.sum(z ** 2, (1, 2, 3)) / (2 * self.sigma_max ** 2)\n",
    "\n",
    "  def discretize(self, x, t):\n",
    "    \"\"\"SMLD(NCSN) discretization.\"\"\"\n",
    "    timestep = (t * (self.N - 1) / self.T).int64()\n",
    "    sigma = self.discrete_sigmas[timestep]\n",
    "    adjacent_sigma = jt.where(timestep == 0, jt.zeros_like(t),\n",
    "                                 self.discrete_sigmas[timestep - 1])\n",
    "    f = jt.zeros_like(x)\n",
    "    G = jt.sqrt(sigma ** 2 - adjacent_sigma ** 2)\n",
    "    return f, G\n",
    "\n",
    "# ç¡®ä¿Jittorä½¿ç”¨CPUï¼ˆå¦‚éœ€GPUå¯æ”¹ä¸ºjt.flags.use_cuda = 1ï¼‰\n",
    "jt.flags.use_cuda = 0\n",
    "\n",
    "def test_sde_base_methods(sde, batch_size=2, img_size=32, channels=3):\n",
    "    \"\"\"æµ‹è¯•SDEçš„åŸºç¡€æ–¹æ³•\"\"\"\n",
    "    # åˆ›å»ºæµ‹è¯•è¾“å…¥\n",
    "    x = jt.randn(batch_size, channels, img_size, img_size)  # éšæœºå›¾åƒæ•°æ®\n",
    "    t = jt.rand(batch_size)  # éšæœºæ—¶é—´æ­¥ [0,1)\n",
    "    \n",
    "    # æµ‹è¯•sdeæ–¹æ³•\n",
    "    drift, diffusion = sde.sde(x, t)\n",
    "    assert drift.shape == x.shape, f\"Driftå½¢çŠ¶é”™è¯¯: {drift.shape} vs {x.shape}\"\n",
    "    assert diffusion.shape == (batch_size,), f\"Diffusionå½¢çŠ¶é”™è¯¯: {diffusion.shape} vs ({batch_size},)\"\n",
    "    \n",
    "    # æµ‹è¯•marginal_probæ–¹æ³•\n",
    "    mean, std = sde.marginal_prob(x, t)\n",
    "    assert mean.shape == x.shape, f\"Meanå½¢çŠ¶é”™è¯¯: {mean.shape} vs {x.shape}\"\n",
    "    assert std.shape == (batch_size,), f\"Stdå½¢çŠ¶é”™è¯¯: {std.shape} vs ({batch_size},)\"\n",
    "    \n",
    "    # æµ‹è¯•prior_samplingæ–¹æ³•\n",
    "    sample_shape = (batch_size, channels, img_size, img_size)\n",
    "    prior_sample = sde.prior_sampling(sample_shape)\n",
    "    assert prior_sample.shape == sample_shape, f\"å…ˆéªŒé‡‡æ ·å½¢çŠ¶é”™è¯¯: {prior_sample.shape} vs {sample_shape}\"\n",
    "    \n",
    "    # æµ‹è¯•prior_logpæ–¹æ³•\n",
    "    logp = sde.prior_logp(prior_sample)\n",
    "    assert logp.shape == (batch_size,), f\"å…ˆéªŒlogpå½¢çŠ¶é”™è¯¯: {logp.shape} vs ({batch_size},)\"\n",
    "    \n",
    "    # æµ‹è¯•discretizeæ–¹æ³•\n",
    "    f, G = sde.discretize(x, t)\n",
    "    assert f.shape == x.shape, f\"Discretize få½¢çŠ¶é”™è¯¯: {f.shape} vs {x.shape}\"\n",
    "    assert G.shape == (batch_size,), f\"Discretize Gå½¢çŠ¶é”™è¯¯: {G.shape} vs ({batch_size},)\"\n",
    "    \n",
    "    print(f\"{sde.__class__.__name__}åŸºç¡€æ–¹æ³•æµ‹è¯•é€šè¿‡\")\n",
    "\n",
    "def test_reverse_sde(sde, batch_size=2, img_size=32, channels=3):\n",
    "    \"\"\"æµ‹è¯•åå‘SDE\"\"\"\n",
    "    # å®šä¹‰ç®€å•çš„scoreå‡½æ•°ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰\n",
    "    def score_fn(x, t):\n",
    "        return jt.zeros_like(x)  # é›¶å¾—åˆ†å‡½æ•°\n",
    "    \n",
    "    # åˆ›å»ºåå‘SDE\n",
    "    rsde = sde.reverse(score_fn)\n",
    "    \n",
    "    # æµ‹è¯•åå‘SDEçš„åŸºç¡€å±æ€§\n",
    "    assert rsde.T == sde.T, \"åå‘SDEçš„ç»ˆæ­¢æ—¶é—´é”™è¯¯\"\n",
    "    \n",
    "    # æµ‹è¯•åå‘SDEçš„sdeæ–¹æ³•\n",
    "    x = jt.randn(batch_size, channels, img_size, img_size)\n",
    "    t = jt.rand(batch_size)\n",
    "    drift, diffusion = rsde.sde(x, t)\n",
    "    assert drift.shape == x.shape, f\"åå‘SDE Driftå½¢çŠ¶é”™è¯¯: {drift.shape} vs {x.shape}\"\n",
    "    assert diffusion.shape == (batch_size,), f\"åå‘SDE Diffusionå½¢çŠ¶é”™è¯¯: {diffusion.shape} vs ({batch_size},)\"\n",
    "    \n",
    "    # æµ‹è¯•åå‘SDEçš„discretizeæ–¹æ³•\n",
    "    f, G = rsde.discretize(x, t)\n",
    "    assert f.shape == x.shape, f\"åå‘SDE discretize få½¢çŠ¶é”™è¯¯: {f.shape} vs {x.shape}\"\n",
    "    assert G.shape == (batch_size,), f\"åå‘SDE discretize Gå½¢çŠ¶é”™è¯¯: {G.shape} vs ({batch_size},)\"\n",
    "    \n",
    "    print(f\"{sde.__class__.__name__}åå‘SDEæµ‹è¯•é€šè¿‡\")\n",
    "\n",
    "def test_vpsde():\n",
    "    \"\"\"æµ‹è¯•VPSDEç±»\"\"\"\n",
    "    sde = VPSDE(beta_min=0.1, beta_max=20, N=1000)\n",
    "    test_sde_base_methods(sde)\n",
    "    test_reverse_sde(sde)\n",
    "\n",
    "def test_subvpsde():\n",
    "    \"\"\"æµ‹è¯•subVPSDEç±»\"\"\"\n",
    "    sde = subVPSDE(beta_min=0.1, beta_max=20, N=1000)\n",
    "    test_sde_base_methods(sde)\n",
    "    test_reverse_sde(sde)\n",
    "\n",
    "def test_vesde():\n",
    "    \"\"\"æµ‹è¯•VESDEç±»\"\"\"\n",
    "    sde = VESDE(sigma_min=0.01, sigma_max=50, N=1000)\n",
    "    test_sde_base_methods(sde)\n",
    "    test_reverse_sde(sde)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è¿è¡Œæ‰€æœ‰æµ‹è¯•\n",
    "    test_vpsde()\n",
    "    test_subvpsde()\n",
    "    test_vesde()\n",
    "    print(\"æ‰€æœ‰SDEæµ‹è¯•å‡é€šè¿‡ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c131b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "import numpy as np\n",
    "import traceback\n",
    "from sampling import (\n",
    "    get_predictor, get_corrector, get_pc_sampler, get_ode_sampler,\n",
    "    EulerMaruyamaPredictor, ReverseDiffusionPredictor, AncestralSamplingPredictor,\n",
    "    LangevinCorrector, NonePredictor, NoneCorrector\n",
    ")\n",
    "from sde_lib import VPSDE, VESDE, subVPSDE\n",
    "\n",
    "\n",
    "def setup_test_env():\n",
    "    \"\"\"åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒï¼šå›ºå®šç§å­ã€æ‰“å°è®¾å¤‡ä¿¡æ¯\"\"\"\n",
    "    jt.set_seed(42)\n",
    "    device_mode = \"GPU\" if jt.flags.use_cuda else \"CPU\"\n",
    "    print(f\"ã€æµ‹è¯•ç¯å¢ƒã€‘è®¾å¤‡ï¼š{device_mode} | Jittorç‰ˆæœ¬ï¼š{jt.__version__} | éšæœºç§å­ï¼š42\\n\")\n",
    "    return device_mode\n",
    "\n",
    "\n",
    "def simple_score_fn(x, t):\n",
    "    \"\"\"ç®€åŒ–åˆ†æ•°å‡½æ•°ï¼ˆè¿”å›é›¶å¼ é‡ï¼Œé¿å…ä¾èµ–å¤æ‚æ¨¡å‹ï¼‰\"\"\"\n",
    "    return jt.zeros_like(x)\n",
    "\n",
    "\n",
    "def print_tensor_info(tensor, name, step):\n",
    "    \"\"\"æ‰“å°å¼ é‡çš„å…³é”®ä¿¡æ¯ï¼ˆç±»å‹ã€å½¢çŠ¶ã€è®¾å¤‡ï¼‰ï¼Œç”¨äºå®šä½ç±»å‹é”™è¯¯\"\"\"\n",
    "    if hasattr(tensor, \"shape\"):\n",
    "        shape_str = tensor.shape\n",
    "    else:\n",
    "        shape_str = \"æ— shapeå±æ€§\"\n",
    "    \n",
    "    if jt.flags.use_cuda and hasattr(tensor, \"device\"):\n",
    "        device_str = tensor.device\n",
    "    else:\n",
    "        device_str = \"CPU\" if not jt.flags.use_cuda else \"GPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\"\n",
    "    \n",
    "    print(f\"  [{step}] {name}ï¼š\")\n",
    "    print(f\"    - ç±»å‹ï¼š{type(tensor)}\")\n",
    "    print(f\"    - å½¢çŠ¶ï¼š{shape_str}\")\n",
    "    print(f\"    - è®¾å¤‡ï¼š{device_str}\")\n",
    "    print(f\"    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼š{callable(tensor)}\\n\")  # å…³é”®ï¼šåˆ¤æ–­æ˜¯å¦æ˜¯æ–¹æ³•å¯¹è±¡\n",
    "\n",
    "\n",
    "def test_step_wrapper(test_func, test_name):\n",
    "    \"\"\"æµ‹è¯•æ­¥éª¤åŒ…è£…å™¨ï¼šæ•è·å¼‚å¸¸å¹¶æ‰“å°è¯¦ç»†å †æ ˆ\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ã€æµ‹è¯•é˜¶æ®µã€‘{test_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    try:\n",
    "        test_func()\n",
    "        print(f\"ã€æµ‹è¯•ç»“æœã€‘{test_name} âœ… é€šè¿‡\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"ã€æµ‹è¯•ç»“æœã€‘{test_name} âŒ å¤±è´¥\")\n",
    "        print(f\"ã€é”™è¯¯ç±»å‹ã€‘{type(e).__name__}: {str(e)}\")\n",
    "        print(f\"ã€é”™è¯¯å †æ ˆã€‘\\n{traceback.format_exc()}\\n\")\n",
    "        raise  # ç»ˆæ­¢æµ‹è¯•ï¼Œä¼˜å…ˆè§£å†³åº•å±‚é”™è¯¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b269ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€æµ‹è¯•ç¯å¢ƒã€‘è®¾å¤‡ï¼šGPU | Jittorç‰ˆæœ¬ï¼š1.3.9.14 | éšæœºç§å­ï¼š42\n",
      "\n",
      "============================================================\n",
      "ã€æµ‹è¯•é˜¶æ®µã€‘1. SDEå±æ€§åˆæ³•æ€§æµ‹è¯•\n",
      "============================================================\n",
      "ã€SDEç±»å‹ã€‘VPSDE\n",
      "  [SDE-1] VPSDE.discrete_betasï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[100,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [SDE-1] VPSDE.alphasï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[100,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "----------------------------------------\n",
      "ã€SDEç±»å‹ã€‘VESDE\n",
      "  [SDE-1] VESDE.discrete_sigmasï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[100,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "----------------------------------------\n",
      "ã€SDEç±»å‹ã€‘subVPSDE\n",
      "  [SDE-1] subVPSDE.discrete_betasï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[100,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [SDE-1] subVPSDE.alphasï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[100,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "----------------------------------------\n",
      "ã€æµ‹è¯•ç»“æœã€‘1. SDEå±æ€§åˆæ³•æ€§æµ‹è¯• âœ… é€šè¿‡\n",
      "\n",
      "============================================================\n",
      "ã€æµ‹è¯•é˜¶æ®µã€‘2. åŸºç¡€é¢„æµ‹å™¨æµ‹è¯•\n",
      "============================================================\n",
      "ã€æµ‹è¯•é¢„æµ‹å™¨ã€‘EulerMaruyamaPredictor\n",
      "  [Pred-1] EulerMaruyamaPredictorå®ä¾‹ï¼š\n",
      "    - ç±»å‹ï¼š<class 'sampling.EulerMaruyamaPredictor'>\n",
      "    - å½¢çŠ¶ï¼šæ— shapeå±æ€§\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Pred-2] è¾“å…¥xç±»å‹ï¼š<class 'jittor.jittor_core.Var'> | è¾“å…¥tç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "  [Pred-3] è¾“å‡ºéªŒè¯é€šè¿‡ï¼šx_outå½¢çŠ¶=[2,3,32,32,] | ç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "ã€æµ‹è¯•é¢„æµ‹å™¨ã€‘ReverseDiffusionPredictor\n",
      "  [Pred-1] ReverseDiffusionPredictorå®ä¾‹ï¼š\n",
      "    - ç±»å‹ï¼š<class 'sampling.ReverseDiffusionPredictor'>\n",
      "    - å½¢çŠ¶ï¼šæ— shapeå±æ€§\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Pred-2] è¾“å…¥xç±»å‹ï¼š<class 'jittor.jittor_core.Var'> | è¾“å…¥tç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "  [Pred-3] è¾“å‡ºéªŒè¯é€šè¿‡ï¼šx_outå½¢çŠ¶=[2,3,32,32,] | ç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "ã€æµ‹è¯•é¢„æµ‹å™¨ã€‘NonePredictor\n",
      "  [Pred-1] NonePredictorå®ä¾‹ï¼š\n",
      "    - ç±»å‹ï¼š<class 'sampling.NonePredictor'>\n",
      "    - å½¢çŠ¶ï¼šæ— shapeå±æ€§\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Pred-2] è¾“å…¥xç±»å‹ï¼š<class 'jittor.jittor_core.Var'> | è¾“å…¥tç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "  [Pred-3] è¾“å‡ºéªŒè¯é€šè¿‡ï¼šx_outå½¢çŠ¶=[2,3,32,32,] | ç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "ã€æµ‹è¯•ç»“æœã€‘2. åŸºç¡€é¢„æµ‹å™¨æµ‹è¯• âœ… é€šè¿‡\n",
      "\n",
      "============================================================\n",
      "ã€æµ‹è¯•é˜¶æ®µã€‘3. AncestralSamplingPredictoré‡ç‚¹æµ‹è¯•\n",
      "============================================================\n",
      "ã€é‡ç‚¹æµ‹è¯•ã€‘AncestralSamplingPredictor + VPSDE\n",
      "  [Anc-1] é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼š<class 'sampling.AncestralSamplingPredictor'>\n",
      "  [Anc-2] è¿›å…¥VPSDEåˆ†æ”¯ï¼ˆvpsde_update_fnï¼‰\n",
      "  [Anc-3a] timestepï¼ˆæ—¶é—´æ­¥ç´¢å¼•ï¼‰ï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[2,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-3b] sde.discrete_betasï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[100,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-3c] betaï¼ˆç´¢å¼•åï¼‰ï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[2,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-3d] scoreï¼ˆåˆ†æ•°å‡½æ•°è¾“å‡ºï¼‰ï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[2,3,32,32,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-4] VPSDEåˆ†æ”¯æµ‹è¯•é€šè¿‡ï¼šx_outå½¢çŠ¶=[2,3,32,32,]\n",
      "\n",
      "ã€é‡ç‚¹æµ‹è¯•ã€‘AncestralSamplingPredictor + VESDE\n",
      "  [Anc-1] é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼š<class 'sampling.AncestralSamplingPredictor'>\n",
      "  [Anc-2] è¿›å…¥VESDEåˆ†æ”¯ï¼ˆvesde_update_fnï¼‰\n",
      "  [Anc-2a] timestepï¼ˆæ—¶é—´æ­¥ç´¢å¼•ï¼‰ï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[2,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-2b] sde.discrete_sigmasï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[100,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-2c] sigmaï¼ˆç´¢å¼•åï¼‰ï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[2,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-2d] scoreï¼ˆåˆ†æ•°å‡½æ•°è¾“å‡ºï¼‰ï¼š\n",
      "    - ç±»å‹ï¼š<class 'jittor.jittor_core.Var'>\n",
      "    - å½¢çŠ¶ï¼š[2,3,32,32,]\n",
      "    - è®¾å¤‡ï¼šGPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\n",
      "    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼šFalse\n",
      "\n",
      "  [Anc-4] VESDEåˆ†æ”¯æµ‹è¯•é€šè¿‡ï¼šx_outå½¢çŠ¶=[2,3,32,32,]\n",
      "\n",
      "ã€æµ‹è¯•ç»“æœã€‘3. AncestralSamplingPredictoré‡ç‚¹æµ‹è¯• âœ… é€šè¿‡\n",
      "\n",
      "============================================================\n",
      "ã€æµ‹è¯•é˜¶æ®µã€‘4. æ ¡æ­£å™¨æµ‹è¯•\n",
      "============================================================\n",
      "ã€æ ¡æ­£å™¨æµ‹è¯•ã€‘SDEç±»å‹ï¼šVPSDE\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šLangevinCorrector\n",
      "  [Corr-2] LangevinCorrector æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šAnnealedLangevinDynamics\n",
      "  [Corr-2] AnnealedLangevinDynamics æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šNoneCorrector\n",
      "  [Corr-2] NoneCorrector æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "ã€æ ¡æ­£å™¨æµ‹è¯•ã€‘SDEç±»å‹ï¼šVESDE\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šLangevinCorrector\n",
      "  [Corr-2] LangevinCorrector æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šAnnealedLangevinDynamics\n",
      "  [Corr-2] AnnealedLangevinDynamics æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šNoneCorrector\n",
      "  [Corr-2] NoneCorrector æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "ã€æ ¡æ­£å™¨æµ‹è¯•ã€‘SDEç±»å‹ï¼šsubVPSDE\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šLangevinCorrector\n",
      "  [Corr-2] LangevinCorrector æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šAnnealedLangevinDynamics\n",
      "  [Corr-2] AnnealedLangevinDynamics æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼šNoneCorrector\n",
      "  [Corr-2] NoneCorrector æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹=<class 'jittor.jittor_core.Var'>\n",
      "\n",
      "ã€æµ‹è¯•ç»“æœã€‘4. æ ¡æ­£å™¨æµ‹è¯• âœ… é€šè¿‡\n",
      "\n",
      "============================================================\n",
      "ã€æµ‹è¯•é˜¶æ®µã€‘5. PCé‡‡æ ·å™¨å…¨æµç¨‹æµ‹è¯•\n",
      "============================================================\n",
      "ã€PCé‡‡æ ·å™¨æµ‹è¯•ã€‘é…ç½®ï¼šVPSDE + EulerMaruyama + Langevin | æ‰¹é‡=2 | å½¢çŠ¶=(2, 3, 32, 32)\n",
      "  [PC-1] å¼€å§‹é‡‡æ ·ï¼ˆå…±50æ­¥ï¼‰...\n",
      "ã€æµ‹è¯•ç»“æœã€‘5. PCé‡‡æ ·å™¨å…¨æµç¨‹æµ‹è¯• âŒ å¤±è´¥\n",
      "ã€é”™è¯¯ç±»å‹ã€‘AttributeError: 'function' object has no attribute 'eval'\n",
      "ã€é”™è¯¯å †æ ˆã€‘\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-39c350c74da2>\", line 53, in test_step_wrapper\n",
      "    test_func()\n",
      "  File \"<ipython-input-2-39c350c74da2>\", line 297, in test_pc_sampler_full\n",
      "    samples, nfe = pc_sampler(model=dummy_model)\n",
      "  File \"/home/a516/score_sde_jittor/sampling.py\", line 406, in pc_sampler\n",
      "    x, x_mean = corrector_update_fn(x, vec_t, model=model)\n",
      "  File \"/home/a516/score_sde_jittor/sampling.py\", line 352, in shared_corrector_update_fn\n",
      "    return corrector_obj.update_fn(x, t)\n",
      "  File \"/home/a516/score_sde_jittor/sampling.py\", line 274, in update_fn\n",
      "    grad = score_fn(x, t)\n",
      "  File \"/home/a516/score_sde_jittor/models/utils.py\", line 154, in score_fn\n",
      "    score = model_fn(x, labels)\n",
      "  File \"/home/a516/score_sde_jittor/models/utils.py\", line 118, in model_fn\n",
      "    model.eval()\n",
      "AttributeError: 'function' object has no attribute 'eval'\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "âŒ å…¨æµç¨‹æµ‹è¯•å¤±è´¥ï¼šAttributeError: 'function' object has no attribute 'eval'\n",
      "ğŸ’¡ å…³é”®æ’æŸ¥å»ºè®®ï¼š\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import jittor as jt\n",
    "import numpy as np\n",
    "import traceback\n",
    "from scipy import integrate  # ODEé‡‡æ ·ä¾èµ–\n",
    "# å¯¼å…¥å¾…æµ‹è¯•çš„é‡‡æ ·æ¨¡å—å’ŒSDEå®šä¹‰\n",
    "from sampling import (\n",
    "    get_predictor, get_corrector, get_pc_sampler, get_ode_sampler,\n",
    "    EulerMaruyamaPredictor, ReverseDiffusionPredictor, AncestralSamplingPredictor,\n",
    "    LangevinCorrector, AnnealedLangevinDynamics, NonePredictor, NoneCorrector\n",
    ")\n",
    "from sde_lib import VPSDE, VESDE, subVPSDE\n",
    "\n",
    "\n",
    "# -------------------------- å…¨å±€æµ‹è¯•å·¥å…·å‡½æ•° --------------------------\n",
    "def setup_test_env():\n",
    "    \"\"\"åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒï¼šå›ºå®šç§å­ã€æ‰“å°è®¾å¤‡ä¿¡æ¯\"\"\"\n",
    "    jt.set_seed(42)\n",
    "    device_mode = \"GPU\" if jt.flags.use_cuda else \"CPU\"\n",
    "    print(f\"ã€æµ‹è¯•ç¯å¢ƒã€‘è®¾å¤‡ï¼š{device_mode} | Jittorç‰ˆæœ¬ï¼š{jt.__version__} | éšæœºç§å­ï¼š42\\n\")\n",
    "    return device_mode\n",
    "\n",
    "\n",
    "def simple_score_fn(x, t):\n",
    "    \"\"\"ç®€åŒ–åˆ†æ•°å‡½æ•°ï¼ˆè¿”å›é›¶å¼ é‡ï¼Œé¿å…ä¾èµ–å¤æ‚æ¨¡å‹ï¼‰\"\"\"\n",
    "    return jt.zeros_like(x)\n",
    "\n",
    "\n",
    "def print_tensor_info(tensor, name, step):\n",
    "    \"\"\"æ‰“å°å¼ é‡çš„å…³é”®ä¿¡æ¯ï¼ˆç±»å‹ã€å½¢çŠ¶ã€è®¾å¤‡ï¼‰ï¼Œç”¨äºå®šä½ç±»å‹é”™è¯¯\"\"\"\n",
    "    if hasattr(tensor, \"shape\"):\n",
    "        shape_str = tensor.shape\n",
    "    else:\n",
    "        shape_str = \"æ— shapeå±æ€§\"\n",
    "    \n",
    "    if jt.flags.use_cuda and hasattr(tensor, \"device\"):\n",
    "        device_str = tensor.device\n",
    "    else:\n",
    "        device_str = \"CPU\" if not jt.flags.use_cuda else \"GPUï¼ˆJittorè‡ªåŠ¨ç®¡ç†ï¼‰\"\n",
    "    \n",
    "    print(f\"  [{step}] {name}ï¼š\")\n",
    "    print(f\"    - ç±»å‹ï¼š{type(tensor)}\")\n",
    "    print(f\"    - å½¢çŠ¶ï¼š{shape_str}\")\n",
    "    print(f\"    - è®¾å¤‡ï¼š{device_str}\")\n",
    "    print(f\"    - æ˜¯å¦ä¸ºæ–¹æ³•ï¼š{callable(tensor)}\\n\")  # å…³é”®ï¼šåˆ¤æ–­æ˜¯å¦æ˜¯æ–¹æ³•å¯¹è±¡\n",
    "\n",
    "\n",
    "def test_step_wrapper(test_func, test_name):\n",
    "    \"\"\"æµ‹è¯•æ­¥éª¤åŒ…è£…å™¨ï¼šæ•è·å¼‚å¸¸å¹¶æ‰“å°è¯¦ç»†å †æ ˆ\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ã€æµ‹è¯•é˜¶æ®µã€‘{test_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    try:\n",
    "        test_func()\n",
    "        print(f\"ã€æµ‹è¯•ç»“æœã€‘{test_name} âœ… é€šè¿‡\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"ã€æµ‹è¯•ç»“æœã€‘{test_name} âŒ å¤±è´¥\")\n",
    "        print(f\"ã€é”™è¯¯ç±»å‹ã€‘{type(e).__name__}: {str(e)}\")\n",
    "        print(f\"ã€é”™è¯¯å †æ ˆã€‘\\n{traceback.format_exc()}\\n\")\n",
    "        raise  # ç»ˆæ­¢æµ‹è¯•ï¼Œä¼˜å…ˆè§£å†³åº•å±‚é”™è¯¯\n",
    "\n",
    "\n",
    "# -------------------------- é˜¶æ®µ1ï¼šæµ‹è¯•SDEå±æ€§åˆæ³•æ€§ --------------------------\n",
    "def test_sde_attributes():\n",
    "    \"\"\"æµ‹è¯•SDEç±»çš„å…³é”®å±æ€§æ˜¯å¦ä¸ºå¼ é‡ï¼ˆéæ–¹æ³•ï¼‰\"\"\"\n",
    "    # åˆå§‹åŒ–3ç±»SDEï¼ˆè¦†ç›–æ‰€æœ‰ä½¿ç”¨åœºæ™¯ï¼‰\n",
    "    sde_configs = [\n",
    "        (\"VPSDE\", VPSDE(beta_min=0.1, beta_max=20, N=100)),\n",
    "        (\"VESDE\", VESDE(sigma_min=0.01, sigma_max=50, N=100)),\n",
    "        (\"subVPSDE\", subVPSDE(beta_min=0.1, beta_max=20, N=100))\n",
    "    ]\n",
    "    \n",
    "    # éªŒè¯æ¯ä¸ªSDEçš„å…³é”®å±æ€§\n",
    "    for sde_name, sde in sde_configs:\n",
    "        print(f\"ã€SDEç±»å‹ã€‘{sde_name}\")\n",
    "        # å¾…éªŒè¯çš„å±æ€§ï¼ˆé”®ï¼šå±æ€§åï¼Œå€¼ï¼šæ˜¯å¦å¿…é¡»å­˜åœ¨ï¼‰\n",
    "        required_attrs = {\n",
    "            \"discrete_betas\": sde_name in [\"VPSDE\", \"subVPSDE\"],  # VESDEæ— æ­¤å±æ€§\n",
    "            \"discrete_sigmas\": sde_name == \"VESDE\",               # ä»…VESDEæœ‰æ­¤å±æ€§\n",
    "            \"alphas\": sde_name in [\"VPSDE\", \"subVPSDE\"]           # VESDEæ— æ­¤å±æ€§\n",
    "        }\n",
    "        \n",
    "        for attr_name, is_required in required_attrs.items():\n",
    "            if is_required:\n",
    "                # æ£€æŸ¥å±æ€§æ˜¯å¦å­˜åœ¨\n",
    "                assert hasattr(sde, attr_name), f\"{sde_name} ç¼ºå°‘å±æ€§ {attr_name}\"\n",
    "                attr_val = getattr(sde, attr_name)\n",
    "                \n",
    "                # æ‰“å°å±æ€§è¯¦ç»†ä¿¡æ¯\n",
    "                print_tensor_info(attr_val, f\"{sde_name}.{attr_name}\", step=f\"SDE-1\")\n",
    "                \n",
    "                # æ ¸å¿ƒæ–­è¨€ï¼šå±æ€§å¿…é¡»æ˜¯Jittorå¼ é‡ï¼Œä¸”ä¸æ˜¯æ–¹æ³•\n",
    "                assert isinstance(attr_val, jt.Var), f\"{sde_name}.{attr_name} ä¸æ˜¯jt.Varï¼ˆå½“å‰ç±»å‹ï¼š{type(attr_val)}ï¼‰\"\n",
    "                assert not callable(attr_val), f\"{sde_name}.{attr_name} æ˜¯æ–¹æ³•å¯¹è±¡ï¼ˆä¸å¯ç´¢å¼•ï¼‰\"\n",
    "            else:\n",
    "                # éªŒè¯éå¿…éœ€å±æ€§ä¸å­˜åœ¨\n",
    "                assert not hasattr(sde, attr_name), f\"{sde_name} ä¸åº”æœ‰å±æ€§ {attr_name}\"\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# -------------------------- é˜¶æ®µ2ï¼šæµ‹è¯•é¢„æµ‹å™¨ --------------------------\n",
    "def test_basic_predictors():\n",
    "    \"\"\"æµ‹è¯•æ— é”™è¯¯çš„åŸºç¡€é¢„æµ‹å™¨ï¼Œç¡®ä¿ç¯å¢ƒæ­£å¸¸\"\"\"\n",
    "    batch_size = 2\n",
    "    img_shape = (batch_size, 3, 32, 32)  # (B, C, H, W)\n",
    "    t = jt.ones(batch_size) * 0.5  # æ—¶é—´æ­¥ï¼ˆç»Ÿä¸€ä¸º0.5ï¼‰\n",
    "    sde = VPSDE(N=100)  # ç”¨VPSDEæµ‹è¯•åŸºç¡€é¢„æµ‹å™¨\n",
    "    x = jt.randn(*img_shape)  # éšæœºè¾“å…¥\n",
    "    \n",
    "    # å¾…æµ‹è¯•çš„åŸºç¡€é¢„æµ‹å™¨\n",
    "    basic_predictors = [\n",
    "        (\"EulerMaruyamaPredictor\", EulerMaruyamaPredictor),\n",
    "        (\"ReverseDiffusionPredictor\", ReverseDiffusionPredictor),\n",
    "        (\"NonePredictor\", NonePredictor)\n",
    "    ]\n",
    "    \n",
    "    for pred_name, pred_cls in basic_predictors:\n",
    "        print(f\"ã€æµ‹è¯•é¢„æµ‹å™¨ã€‘{pred_name}\")\n",
    "        # 1. åˆå§‹åŒ–é¢„æµ‹å™¨\n",
    "        pred = pred_cls(sde=sde, score_fn=simple_score_fn, probability_flow=False)\n",
    "        print_tensor_info(pred, f\"{pred_name}å®ä¾‹\", step=\"Pred-1\")\n",
    "        \n",
    "        # 2. è°ƒç”¨update_fnï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰\n",
    "        print(f\"  [Pred-2] è¾“å…¥xç±»å‹ï¼š{type(x)} | è¾“å…¥tç±»å‹ï¼š{type(t)}\")\n",
    "        x_out, x_mean_out = pred.update_fn(x, t)\n",
    "        \n",
    "        # 3. éªŒè¯è¾“å‡º\n",
    "        assert x_out.shape == img_shape, f\"è¾“å‡ºå½¢çŠ¶é”™è¯¯ï¼š{x_out.shape} vs {img_shape}\"\n",
    "        assert isinstance(x_out, jt.Var), f\"è¾“å‡ºä¸æ˜¯jt.Varï¼ˆç±»å‹ï¼š{type(x_out)}ï¼‰\"\n",
    "        print(f\"  [Pred-3] è¾“å‡ºéªŒè¯é€šè¿‡ï¼šx_outå½¢çŠ¶={x_out.shape} | ç±»å‹={type(x_out)}\\n\")\n",
    "\n",
    "\n",
    "def test_ancestral_sampling_predictor():\n",
    "    \"\"\"é€è¡Œæµ‹è¯•AncestralSamplingPredictorï¼Œå®šä½æ–¹æ³•ç´¢å¼•é”™è¯¯\"\"\"\n",
    "    batch_size = 2\n",
    "    img_shape = (batch_size, 3, 32, 32)\n",
    "    t = jt.ones(batch_size) * 0.5  # æ—¶é—´æ­¥\n",
    "    x = jt.randn(*img_shape)        # éšæœºè¾“å…¥\n",
    "    \n",
    "    # æµ‹è¯•2ç±»SDEï¼ˆAncestralä»…æ”¯æŒVPSDE/VESDEï¼‰\n",
    "    sde_list = [\n",
    "        (\"VPSDE\", VPSDE(beta_min=0.1, beta_max=20, N=100)),\n",
    "        (\"VESDE\", VESDE(sigma_min=0.01, sigma_max=50, N=100))\n",
    "    ]\n",
    "    \n",
    "    for sde_name, sde in sde_list:\n",
    "        print(f\"ã€é‡ç‚¹æµ‹è¯•ã€‘AncestralSamplingPredictor + {sde_name}\")\n",
    "        # 1. åˆå§‹åŒ–Ancestralé¢„æµ‹å™¨\n",
    "        pred = AncestralSamplingPredictor(\n",
    "            sde=sde, score_fn=simple_score_fn, probability_flow=False\n",
    "        )\n",
    "        print(f\"  [Anc-1] é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼š{type(pred)}\")\n",
    "        \n",
    "        # 2. æ‹†è§£update_fné€»è¾‘ï¼ˆåˆ†VESDE/VPSDEåˆ†æ”¯ï¼‰\n",
    "        if isinstance(sde, VESDE):\n",
    "            print(\"  [Anc-2] è¿›å…¥VESDEåˆ†æ”¯ï¼ˆvesde_update_fnï¼‰\")\n",
    "            # é€è¡Œæ‰§è¡Œvesde_update_fnï¼Œæ‰“å°å…³é”®å¯¹è±¡\n",
    "            timestep = (t * (sde.N - 1) / sde.T).long()\n",
    "            print_tensor_info(timestep, \"timestepï¼ˆæ—¶é—´æ­¥ç´¢å¼•ï¼‰\", step=\"Anc-2a\")\n",
    "            \n",
    "            # å…³é”®ï¼šéªŒè¯sde.discrete_sigmasæ˜¯å¼ é‡ï¼Œä¸”ç´¢å¼•æ“ä½œåˆæ³•\n",
    "            print_tensor_info(sde.discrete_sigmas, \"sde.discrete_sigmas\", step=\"Anc-2b\")\n",
    "            assert isinstance(sde.discrete_sigmas, jt.Var), \"discrete_sigmasä¸æ˜¯å¼ é‡\"\n",
    "            \n",
    "            sigma = sde.discrete_sigmas[timestep]  # å¯èƒ½å‡ºé”™çš„ç´¢å¼•è¡Œ\n",
    "            print_tensor_info(sigma, \"sigmaï¼ˆç´¢å¼•åï¼‰\", step=\"Anc-2c\")\n",
    "            \n",
    "            # ç»§ç»­æ‰§è¡Œå‰©ä½™é€»è¾‘\n",
    "            adjacent_sigma = jt.where(timestep == 0, jt.zeros_like(t), sde.discrete_sigmas[timestep - 1])\n",
    "            score = pred.score_fn(x, t)\n",
    "            print_tensor_info(score, \"scoreï¼ˆåˆ†æ•°å‡½æ•°è¾“å‡ºï¼‰\", step=\"Anc-2d\")\n",
    "            \n",
    "            x_mean = x + score * (sigma **2 - adjacent_sigma** 2)[:, None, None, None]\n",
    "            std = jt.sqrt((adjacent_sigma **2 * (sigma** 2 - adjacent_sigma **2)) / (sigma** 2))\n",
    "            noise = jt.randn_like(x)\n",
    "            x_out = x_mean + std[:, None, None, None] * noise\n",
    "            \n",
    "        else:  # VPSDEåˆ†æ”¯\n",
    "            print(\"  [Anc-2] è¿›å…¥VPSDEåˆ†æ”¯ï¼ˆvpsde_update_fnï¼‰\")\n",
    "            # é€è¡Œæ‰§è¡Œvpsde_update_fnï¼Œæ‰“å°å…³é”®å¯¹è±¡\n",
    "            timestep = (t * (sde.N - 1) / sde.T).long()\n",
    "            print_tensor_info(timestep, \"timestepï¼ˆæ—¶é—´æ­¥ç´¢å¼•ï¼‰\", step=\"Anc-3a\")\n",
    "            \n",
    "            # å…³é”®ï¼šéªŒè¯sde.discrete_betasæ˜¯å¼ é‡ï¼Œä¸”æ— é”™è¯¯è°ƒç”¨\n",
    "            print_tensor_info(sde.discrete_betas, \"sde.discrete_betas\", step=\"Anc-3b\")\n",
    "            assert isinstance(sde.discrete_betas, jt.Var), \"discrete_betasä¸æ˜¯å¼ é‡\"\n",
    "            \n",
    "            # é‡ç‚¹æ’æŸ¥ï¼šç”¨æˆ·ä»£ç ä¸­å¯èƒ½å­˜åœ¨çš„.to[timestep]é”™è¯¯\n",
    "            try:\n",
    "                # ä¿®æ­£ï¼šåˆ é™¤.toï¼ˆJittoræ— éœ€è®¾å¤‡è½¬ç§»ï¼‰ï¼Œç›´æ¥ç´¢å¼•\n",
    "                beta = sde.discrete_betas[timestep]\n",
    "                print_tensor_info(beta, \"betaï¼ˆç´¢å¼•åï¼‰\", step=\"Anc-3c\")\n",
    "            except Exception as e:\n",
    "                print(f\"  [Anc-3c é”™è¯¯] ç´¢å¼•sde.discrete_betasæ—¶å¤±è´¥ï¼š{str(e)}\")\n",
    "                print(f\"  [å…³é”®æ£€æŸ¥] sde.discrete_betas.to æ˜¯å¦å­˜åœ¨ï¼Ÿ{hasattr(sde.discrete_betas, 'to')}\")\n",
    "                if hasattr(sde.discrete_betas, 'to'):\n",
    "                    print(f\"  [å…³é”®æ£€æŸ¥] sde.discrete_betas.to ç±»å‹ï¼š{type(sde.discrete_betas.to)}\")\n",
    "                raise\n",
    "            \n",
    "            # ç»§ç»­æ‰§è¡Œå‰©ä½™é€»è¾‘\n",
    "            score = pred.score_fn(x, t)\n",
    "            print_tensor_info(score, \"scoreï¼ˆåˆ†æ•°å‡½æ•°è¾“å‡ºï¼‰\", step=\"Anc-3d\")\n",
    "            \n",
    "            x_mean = (x + beta[:, None, None, None] * score) / jt.sqrt(1. - beta)[:, None, None, None]\n",
    "            noise = jt.randn_like(x)\n",
    "            x_out = x_mean + jt.sqrt(beta)[:, None, None, None] * noise\n",
    "        \n",
    "        # 3. éªŒè¯æœ€ç»ˆè¾“å‡º\n",
    "        assert x_out.shape == img_shape, f\"Ancestralè¾“å‡ºå½¢çŠ¶é”™è¯¯ï¼š{x_out.shape} vs {img_shape}\"\n",
    "        print(f\"  [Anc-4] {sde_name}åˆ†æ”¯æµ‹è¯•é€šè¿‡ï¼šx_outå½¢çŠ¶={x_out.shape}\\n\")\n",
    "\n",
    "\n",
    "# -------------------------- é˜¶æ®µ3ï¼šæµ‹è¯•æ ¡æ­£å™¨ --------------------------\n",
    "def test_correctors():\n",
    "    \"\"\"æµ‹è¯•æ‰€æœ‰æ ¡æ­£å™¨ï¼Œé‡ç‚¹éªŒè¯alphaçš„ç´¢å¼•åˆæ³•æ€§\"\"\"\n",
    "    batch_size = 2\n",
    "    img_shape = (batch_size, 3, 32, 32)\n",
    "    t = jt.ones(batch_size) * 0.5\n",
    "    x = jt.randn(*img_shape)\n",
    "    snr = 0.1  # ä¿¡å·å™ªå£°æ¯”\n",
    "    n_steps = 1  # æ ¡æ­£å™¨è¿­ä»£æ­¥æ•°\n",
    "    \n",
    "    # æµ‹è¯•ç»„åˆï¼š3ç±»SDE Ã— 3ç±»æ ¡æ­£å™¨\n",
    "    sde_list = [VPSDE(N=100), VESDE(N=100), subVPSDE(N=100)]\n",
    "    corrector_list = [\n",
    "        (\"LangevinCorrector\", LangevinCorrector),\n",
    "        (\"AnnealedLangevinDynamics\", AnnealedLangevinDynamics),\n",
    "        (\"NoneCorrector\", NoneCorrector)\n",
    "    ]\n",
    "    \n",
    "    for sde in sde_list:\n",
    "        sde_name = sde.__class__.__name__\n",
    "        print(f\"ã€æ ¡æ­£å™¨æµ‹è¯•ã€‘SDEç±»å‹ï¼š{sde_name}\")\n",
    "        \n",
    "        for corr_name, corr_cls in corrector_list:\n",
    "            print(f\"  [Corr-1] æµ‹è¯•æ ¡æ­£å™¨ï¼š{corr_name}\")\n",
    "            try:\n",
    "                # 1. åˆå§‹åŒ–æ ¡æ­£å™¨\n",
    "                corr = corr_cls(sde=sde, score_fn=simple_score_fn, snr=snr, n_steps=n_steps)\n",
    "                \n",
    "                # 2. è°ƒç”¨update_fnï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰\n",
    "                x_out, x_mean_out = corr.update_fn(x, t)\n",
    "                \n",
    "                # 3. éªŒè¯è¾“å‡º\n",
    "                assert x_out.shape == img_shape, f\"æ ¡æ­£å™¨è¾“å‡ºå½¢çŠ¶é”™è¯¯ï¼š{x_out.shape} vs {img_shape}\"\n",
    "                print(f\"  [Corr-2] {corr_name} æµ‹è¯•é€šè¿‡ï¼šx_outç±»å‹={type(x_out)}\\n\")\n",
    "                \n",
    "            except NotImplementedError as e:\n",
    "                # æ­£å¸¸ï¼šéƒ¨åˆ†SDEä¸æ”¯æŒæŸäº›æ ¡æ­£å™¨\n",
    "                print(f\"  [Corr-2] è·³è¿‡ï¼š{corr_name} ä¸æ”¯æŒ {sde_name}ï¼ˆ{str(e)}ï¼‰\\n\")\n",
    "            except Exception as e:\n",
    "                # å¼‚å¸¸ï¼šæ‰“å°è¯¦ç»†ä¿¡æ¯\n",
    "                print(f\"  [Corr-2 é”™è¯¯] {corr_name} æµ‹è¯•å¤±è´¥ï¼š{str(e)}\")\n",
    "                # å®šä½alphaç´¢å¼•é—®é¢˜ï¼ˆæ ¡æ­£å™¨å¸¸è§é”™è¯¯ç‚¹ï¼‰\n",
    "                if \"alpha\" in str(e) or \"index\" in str(e):\n",
    "                    timestep = (t * (sde.N - 1) / sde.T).long()\n",
    "                    print(f\"  [é”™è¯¯å®šä½] timestepç±»å‹ï¼š{type(timestep)} | å€¼ï¼š{timestep}\")\n",
    "                    if hasattr(sde, \"alphas\"):\n",
    "                        print(f\"  [é”™è¯¯å®šä½] sde.alphasç±»å‹ï¼š{type(sde.alphas)} | æ˜¯å¦å¯ç´¢å¼•ï¼š{hasattr(sde.alphas, '__getitem__')}\")\n",
    "                raise\n",
    "\n",
    "\n",
    "# -------------------------- é˜¶æ®µ4ï¼šæµ‹è¯•å®Œæ•´é‡‡æ ·æµç¨‹ --------------------------\n",
    "def test_pc_sampler_full():\n",
    "    \"\"\"æµ‹è¯•å®Œæ•´PCé‡‡æ ·æµç¨‹ï¼ˆé¢„æµ‹å™¨+æ ¡æ­£å™¨ç»„åˆï¼‰\"\"\"\n",
    "    # æµ‹è¯•é…ç½®\n",
    "    batch_size = 2\n",
    "    img_shape = (3, 32, 32)  # å•æ ·æœ¬å½¢çŠ¶ (C, H, W)\n",
    "    full_shape = (batch_size, *img_shape)  # æ‰¹é‡å½¢çŠ¶ (B, C, H, W)\n",
    "    sde = VPSDE(N=50)  # ç®€åŒ–æ­¥æ•°ï¼ˆ50æ­¥ï¼‰åŠ å¿«æµ‹è¯•\n",
    "    snr = 0.1\n",
    "    n_steps = 1\n",
    "    denoise = True\n",
    "    \n",
    "    # ç®€åŒ–é€†å½’ä¸€åŒ–å‡½æ•°ï¼ˆæ— å®é™…ç¼©æ”¾ï¼Œä»…è¿”å›åŸå¼ é‡ï¼‰\n",
    "    def inverse_scaler(x):\n",
    "        return x\n",
    "    \n",
    "    print(f\"ã€PCé‡‡æ ·å™¨æµ‹è¯•ã€‘é…ç½®ï¼šVPSDE + EulerMaruyama + Langevin | æ‰¹é‡={batch_size} | å½¢çŠ¶={full_shape}\")\n",
    "    \n",
    "    # 1. åˆ›å»ºPCé‡‡æ ·å™¨\n",
    "    pc_sampler = get_pc_sampler(\n",
    "        sde=sde,\n",
    "        shape=full_shape,\n",
    "        predictor=EulerMaruyamaPredictor,\n",
    "        corrector=LangevinCorrector,\n",
    "        inverse_scaler=inverse_scaler,\n",
    "        snr=snr,\n",
    "        n_steps=n_steps,\n",
    "        continuous=False,\n",
    "        denoise=denoise,\n",
    "        eps=1e-3\n",
    "    )\n",
    "    \n",
    "    # 2. è°ƒç”¨é‡‡æ ·å™¨ï¼ˆä¼ å…¥dummyæ¨¡å‹ï¼Œä»…ç”¨äºç”Ÿæˆscore_fnï¼‰\n",
    "    dummy_model = lambda x, t: simple_score_fn(x, t)\n",
    "    print(f\"  [PC-1] å¼€å§‹é‡‡æ ·ï¼ˆå…±{sde.N}æ­¥ï¼‰...\")\n",
    "    samples, nfe = pc_sampler(model=dummy_model)\n",
    "    \n",
    "    # 3. éªŒè¯é‡‡æ ·ç»“æœ\n",
    "    assert samples.shape == full_shape, f\"PCé‡‡æ ·å™¨è¾“å‡ºå½¢çŠ¶é”™è¯¯ï¼š{samples.shape} vs {full_shape}\"\n",
    "    assert isinstance(samples, jt.Var), f\"PCé‡‡æ ·å™¨è¾“å‡ºä¸æ˜¯jt.Varï¼ˆç±»å‹ï¼š{type(samples)}ï¼‰\"\n",
    "    print(f\"  [PC-2] é‡‡æ ·å®Œæˆï¼šæ ·æœ¬å½¢çŠ¶={samples.shape} | å‡½æ•°è°ƒç”¨æ¬¡æ•°={nfe}\")\n",
    "    print(f\"  [PC-3] PCé‡‡æ ·å™¨å…¨æµç¨‹æµ‹è¯•é€šè¿‡\\n\")\n",
    "\n",
    "\n",
    "def test_ode_sampler_full():\n",
    "    \"\"\"æµ‹è¯•å®Œæ•´ODEé‡‡æ ·æµç¨‹ï¼ˆä¾èµ–scipyæ±‚è§£å™¨ï¼‰\"\"\"\n",
    "    batch_size = 2\n",
    "    img_shape = (3, 32, 32)\n",
    "    full_shape = (batch_size, *img_shape)\n",
    "    sde = VESDE(N=50)  # VESDEé€‚åˆODEæµ‹è¯•\n",
    "    denoise = True\n",
    "    \n",
    "    def inverse_scaler(x):\n",
    "        return x\n",
    "    \n",
    "    print(f\"ã€ODEé‡‡æ ·å™¨æµ‹è¯•ã€‘é…ç½®ï¼šVESDE + RK45æ±‚è§£å™¨ | æ‰¹é‡={batch_size} | å½¢çŠ¶={full_shape}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. åˆ›å»ºODEé‡‡æ ·å™¨\n",
    "        ode_sampler = get_ode_sampler(\n",
    "            sde=sde,\n",
    "            shape=full_shape,\n",
    "            inverse_scaler=inverse_scaler,\n",
    "            denoise=denoise,\n",
    "            method=\"RK45\",\n",
    "            eps=1e-3\n",
    "        )\n",
    "        \n",
    "        # 2. è°ƒç”¨é‡‡æ ·å™¨\n",
    "        dummy_model = lambda x, t: simple_score_fn(x, t)\n",
    "        print(\"  [ODE-1] å¼€å§‹ODEé‡‡æ ·ï¼ˆä¾èµ–scipy.integrateï¼‰...\")\n",
    "        samples, nfe = ode_sampler(model=dummy_model)\n",
    "        \n",
    "        # 3. éªŒè¯ç»“æœ\n",
    "        assert samples.shape == full_shape, f\"ODEé‡‡æ ·å™¨è¾“å‡ºå½¢çŠ¶é”™è¯¯ï¼š{samples.shape} vs {full_shape}\"\n",
    "        print(f\"  [ODE-2] é‡‡æ ·å®Œæˆï¼šæ ·æœ¬å½¢çŠ¶={samples.shape} | ODEæ±‚è§£å™¨è°ƒç”¨æ¬¡æ•°={nfe}\")\n",
    "        print(f\"  [ODE-3] ODEé‡‡æ ·å™¨å…¨æµç¨‹æµ‹è¯•é€šè¿‡\\n\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(f\"  [ODE-é”™è¯¯] ç¼ºå°‘scipyï¼Œè¯·å®‰è£…ï¼špip install scipy\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [ODE-é”™è¯¯] é‡‡æ ·å¤±è´¥ï¼š{str(e)}\")\n",
    "        # å®šä½ODEå‡½æ•°ä¸­çš„from_flattened_numpy/to_flattened_numpyï¼ˆè‹¥ç”¨æˆ·ä»£ç ä¸­å­˜åœ¨ï¼‰\n",
    "        if \"from_flattened_numpy\" in str(e) or \"to_flattened_numpy\" in str(e):\n",
    "            print(\"  [é”™è¯¯å®šä½] æ£€æŸ¥models.utilsä¸­çš„from/to_flattened_numpyæ˜¯å¦é€‚é…Jittor\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# -------------------------- æ‰§è¡Œå…¨æµç¨‹æµ‹è¯• --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 1. åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ\n",
    "        setup_test_env()\n",
    "        \n",
    "        # 2. æŒ‰é˜¶æ®µæ‰§è¡Œæµ‹è¯•ï¼ˆå‰ä¸€é˜¶æ®µå¤±è´¥åˆ™ç»ˆæ­¢ï¼Œé¿å…è¿é”é”™è¯¯ï¼‰\n",
    "        test_step_wrapper(test_sde_attributes, \"1. SDEå±æ€§åˆæ³•æ€§æµ‹è¯•\")\n",
    "        test_step_wrapper(test_basic_predictors, \"2. åŸºç¡€é¢„æµ‹å™¨æµ‹è¯•\")\n",
    "        test_step_wrapper(test_ancestral_sampling_predictor, \"3. AncestralSamplingPredictoré‡ç‚¹æµ‹è¯•\")\n",
    "        test_step_wrapper(test_correctors, \"4. æ ¡æ­£å™¨æµ‹è¯•\")\n",
    "        test_step_wrapper(test_pc_sampler_full, \"5. PCé‡‡æ ·å™¨å…¨æµç¨‹æµ‹è¯•\")\n",
    "        test_step_wrapper(test_ode_sampler_full, \"6. ODEé‡‡æ ·å™¨å…¨æµç¨‹æµ‹è¯•\")\n",
    "        \n",
    "        # 3. æœ€ç»ˆç»“æœ\n",
    "        print(\"=\" * 70)\n",
    "        print(\"ğŸ‰ å…¨æµç¨‹æµ‹è¯•é€šè¿‡ï¼sampling.pyï¼ˆJittorç‰ˆï¼‰æ— ç±»å‹é”™è¯¯\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"âŒ å…¨æµç¨‹æµ‹è¯•å¤±è´¥ï¼š{type(e).__name__}: {str(e)}\")\n",
    "        print(\"ğŸ’¡ å…³é”®æ’æŸ¥å»ºè®®ï¼š\")\n",
    "        if \"'method' object is not subscriptable\" in str(e):\n",
    "            print(\"  - æ£€æŸ¥æ˜¯å¦å­˜åœ¨ 'sde.discrete_betas.to[timestep]' è¿™ç±»ä»£ç ï¼ˆ.toæ˜¯æ–¹æ³•ï¼Œåº”åˆ é™¤ï¼‰\")\n",
    "            print(\"  - ç¡®ä¿æ‰€æœ‰ç´¢å¼•æ“ä½œçš„å¯¹è±¡æ˜¯jt.Varï¼ˆé€šè¿‡é˜¶æ®µ1çš„SDEå±æ€§æµ‹è¯•éªŒè¯ï¼‰\")\n",
    "        print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf642e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0831 17:20:36.021648 04 compiler.py:956] Jittor(1.3.9.14) src: /home/a516/anaconda3/envs/Jittor/lib/python3.8/site-packages/jittor\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:36.026710 04 compiler.py:957] g++ at /usr/bin/g++(12.3.0)\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:36.027513 04 compiler.py:958] cache_path: /home/a516/.cache/jittor/jt1.3.9/g++12.3.0/py3.8.20/Linux-6.6.87.2xef/13thGenIntelRCx37/4832/default\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:36.037754 04 __init__.py:412] Found nvcc(12.8.61) at /usr/local/cuda-12.8/bin/nvcc.\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:36.180715 04 __init__.py:412] Found addr2line(2.42) at /usr/bin/addr2line.\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:36.245548 04 compiler.py:1013] cuda key:cu12.8.61\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:36.712410 04 __init__.py:227] Total mem: 15.43GB, using 5 procs for compiling.\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:36.840692 04 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:37.071908 04 init.cc:63] Found cuda archs: [89,]\u001b[m\n",
      "\u001b[38;5;3m[w 0831 17:20:37.409088 04 compile_extern.py:203] CUDA related path found in LD_LIBRARY_PATH or PATH, This path may cause jittor found the wrong libs, please unset LD_LIBRARY_PATH and remove cuda lib path in Path. \n",
      "Or you can let jittor install cuda for you: `python3.x -m jittor_utils.install_cuda`\u001b[m\n",
      "\u001b[38;5;2m[i 0831 17:20:37.906798 04 cuda_flags.cc:49] CUDA enabled.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•åŸºç¡€åŠŸèƒ½...\n",
      "æµ‹è¯•å‚æ•°: up=1, down=1, pad=(0, 0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Wrong inputs arguments, Please refer to examples(help(jt.ops.code)).\n\nTypes of your inputs are:\n self\t= module,\n args\t= (list, NanoString, list, ),\n kwargs\t= {cuda_src=str, extras=dict, },\n\nThe function declarations are:\n VarHolder* code(NanoVector shape,  NanoString dtype, vector<VarHolder*>&& inputs={},  string&& cpu_src=\"\",  vector<string>&& cpu_grad_src={},  string&& cpu_header=\"\",  string&& cuda_src=\"\",  vector<string>&& cuda_grad_src={},  string&& cuda_header=\"\",  DataMap&& data={})\n vector_to_tuple<VarHolder*> code_(vector<NanoVector>&& shapes,  vector<NanoString>&& dtypes, vector<VarHolder*>&& inputs={},  string&& cpu_src=\"\",  vector<string>&& cpu_grad_src={},  string&& cpu_header=\"\",  string&& cuda_src=\"\",  vector<string>&& cuda_grad_src={},  string&& cuda_header=\"\",  DataMap&& data={})\n vector_to_tuple<VarHolder*> code__(vector<VarHolder*>&& inputs, vector<VarHolder*>&& outputs,  string&& cpu_src=\"\",  vector<string>&& cpu_grad_src={},  string&& cpu_header=\"\",  string&& cuda_src=\"\",  vector<string>&& cuda_grad_src={},  string&& cuda_header=\"\",  DataMap&& data={})\n\nFailed reason:\u001b[38;5;1m[f 0831 17:20:37.909518 04 pyjt_jit_op_maker.cc:17225] Not a valid keyword: extras\u001b[m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e3f375baaeaa>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mtest_upfirdn2d_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mtest_upfirdn2d_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"æ‰€æœ‰æµ‹è¯•é€šè¿‡!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e3f375baaeaa>\u001b[0m in \u001b[0;36mtest_upfirdn2d_basic\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"æµ‹è¯•å‚æ•°: up={up}, down={down}, pad={pad}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# è®¡ç®—é¢„æœŸè¾“å‡ºå½¢çŠ¶\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/score_sde_jittor/op.py\u001b[0m in \u001b[0;36mupfirdn2d\u001b[0;34m(input, kernel, up, down, pad)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;34m\"\"\"ä»…ä¿ç•™GPUè·¯å¾„çš„upfirdn2då®ç°ï¼Œä½¿ç”¨UpFirDn2dç®—å­\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     out = UpFirDn2d.apply(\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/Jittor/lib/python3.8/site-packages/jittor/__init__.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGradHooker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Jittor/lib/python3.8/site-packages/jittor/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1931\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m                 \u001b[0mtaped_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1933\u001b[0;31m         \u001b[0mori_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1934\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mori_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/score_sde_jittor/op.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, input, kernel, up, down, pad)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# è°ƒç”¨Jittorä»£ç ç”Ÿæˆå™¨å®ç°CUDAå†…æ ¸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         return jt.code(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# è¾“å‡ºå½¢çŠ¶\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# è¾“å‡ºæ•°æ®ç±»å‹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Wrong inputs arguments, Please refer to examples(help(jt.ops.code)).\n\nTypes of your inputs are:\n self\t= module,\n args\t= (list, NanoString, list, ),\n kwargs\t= {cuda_src=str, extras=dict, },\n\nThe function declarations are:\n VarHolder* code(NanoVector shape,  NanoString dtype, vector<VarHolder*>&& inputs={},  string&& cpu_src=\"\",  vector<string>&& cpu_grad_src={},  string&& cpu_header=\"\",  string&& cuda_src=\"\",  vector<string>&& cuda_grad_src={},  string&& cuda_header=\"\",  DataMap&& data={})\n vector_to_tuple<VarHolder*> code_(vector<NanoVector>&& shapes,  vector<NanoString>&& dtypes, vector<VarHolder*>&& inputs={},  string&& cpu_src=\"\",  vector<string>&& cpu_grad_src={},  string&& cpu_header=\"\",  string&& cuda_src=\"\",  vector<string>&& cuda_grad_src={},  string&& cuda_header=\"\",  DataMap&& data={})\n vector_to_tuple<VarHolder*> code__(vector<VarHolder*>&& inputs, vector<VarHolder*>&& outputs,  string&& cpu_src=\"\",  vector<string>&& cpu_grad_src={},  string&& cpu_header=\"\",  string&& cuda_src=\"\",  vector<string>&& cuda_grad_src={},  string&& cuda_header=\"\",  DataMap&& data={})\n\nFailed reason:\u001b[38;5;1m[f 0831 17:20:37.909518 04 pyjt_jit_op_maker.cc:17225] Not a valid keyword: extras\u001b[m"
     ]
    }
   ],
   "source": [
    "import jittor as jt\n",
    "import numpy as np\n",
    "from op import upfirdn2d\n",
    "\n",
    "# ç¡®ä¿ä½¿ç”¨CUDA\n",
    "jt.flags.use_cuda = 1\n",
    "\n",
    "def test_upfirdn2d_basic():\n",
    "    # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°\n",
    "    jt.set_seed(42)\n",
    "    \n",
    "    # æµ‹è¯•ç”¨ä¾‹1ï¼šåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
    "    print(\"æµ‹è¯•åŸºç¡€åŠŸèƒ½...\")\n",
    "    batch, channel, height, width = 2, 3, 8, 8\n",
    "    kernel_size = 3\n",
    "    \n",
    "    # åˆ›å»ºéšæœºè¾“å…¥å’Œkernel\n",
    "    input = jt.randn(batch, channel, height, width)\n",
    "    kernel = jt.randn(kernel_size, kernel_size)\n",
    "    \n",
    "    # æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆ\n",
    "    params_list = [\n",
    "        (1, 1, (0, 0)),  # æ— ä¸Šä¸‹é‡‡æ ·ï¼Œæ— å¡«å……\n",
    "        (2, 1, (1, 1)),  # ä¸Šé‡‡æ ·x2ï¼Œæ— ä¸‹é‡‡æ ·ï¼Œå¡«å……1\n",
    "        (1, 2, (1, 1)),  # æ— ä¸Šé‡‡æ ·ï¼Œä¸‹é‡‡æ ·x2ï¼Œå¡«å……1\n",
    "        (2, 2, (2, 2))   # ä¸Šé‡‡æ ·x2+ä¸‹é‡‡æ ·x2ï¼Œå¡«å……2\n",
    "    ]\n",
    "    \n",
    "    for up, down, pad in params_list:\n",
    "        print(f\"æµ‹è¯•å‚æ•°: up={up}, down={down}, pad={pad}\")\n",
    "        output = upfirdn2d(input, kernel, up, down, pad)\n",
    "        \n",
    "        # è®¡ç®—é¢„æœŸè¾“å‡ºå½¢çŠ¶\n",
    "        kernel_h, kernel_w = kernel_size, kernel_size\n",
    "        expected_h = (height * up + pad[0] + pad[1] - kernel_h) // down + 1\n",
    "        expected_w = (width * up + pad[0] + pad[1] - kernel_w) // down + 1\n",
    "        \n",
    "        # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶æ˜¯å¦æ­£ç¡®\n",
    "        assert output.shape == (batch, channel, expected_h, expected_w), \\\n",
    "            f\"å½¢çŠ¶ä¸åŒ¹é…! é¢„æœŸ: {(batch, channel, expected_h, expected_w)}, å®é™…: {output.shape}\"\n",
    "        print(f\"å½¢çŠ¶æ£€æŸ¥é€šè¿‡: {output.shape}\")\n",
    "    \n",
    "    print(\"åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡!\\n\")\n",
    "\n",
    "def test_upfirdn2d_backward():\n",
    "    # æµ‹è¯•ç”¨ä¾‹2ï¼šåå‘ä¼ æ’­æµ‹è¯•\n",
    "    print(\"æµ‹è¯•åå‘ä¼ æ’­...\")\n",
    "    batch, channel, height, width = 1, 2, 4, 4\n",
    "    kernel_size = 3\n",
    "    \n",
    "    # åˆ›å»ºéœ€è¦è®¡ç®—æ¢¯åº¦çš„è¾“å…¥\n",
    "    input = jt.randn(batch, channel, height, width, requires_grad=True)\n",
    "    kernel = jt.randn(kernel_size, kernel_size)\n",
    "    \n",
    "    # å‰å‘è®¡ç®—\n",
    "    output = upfirdn2d(input, kernel, up=2, down=2, pad=(1, 1))\n",
    "    \n",
    "    # è®¡ç®—æŸå¤±ï¼ˆç®€å•æ±‚å’Œï¼‰\n",
    "    loss = output.sum()\n",
    "    \n",
    "    # åå‘ä¼ æ’­\n",
    "    loss.backward()\n",
    "    \n",
    "    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å­˜åœ¨ä¸”å½¢çŠ¶æ­£ç¡®\n",
    "    assert input.grad is not None, \"è¾“å…¥æ¢¯åº¦ä¸å­˜åœ¨!\"\n",
    "    assert input.grad.shape == input.shape, \"æ¢¯åº¦å½¢çŠ¶ä¸åŒ¹é…!\"\n",
    "    \n",
    "    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦ä¸ºéé›¶å€¼ï¼ˆéšæœºè¾“å…¥ä¸‹æ¢¯åº¦åº”ä¸ºéé›¶ï¼‰\n",
    "    assert not jt.allclose(input.grad, jt.zeros_like(input.grad)), \"æ¢¯åº¦å€¼å…¨ä¸ºé›¶!\"\n",
    "    \n",
    "    print(\"åå‘ä¼ æ’­æµ‹è¯•é€šè¿‡!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_upfirdn2d_basic()\n",
    "    test_upfirdn2d_backward()\n",
    "    print(\"æ‰€æœ‰æµ‹è¯•é€šè¿‡!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jittor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
